Model Config:
  -> batch_size: 64
  -> cell_type: lstm
  -> hidden_size: 200
  -> is_training: True
  -> keep_prob: 1.0
  -> learning_rate: 0.002
  -> max_epoch: 50
  -> max_grad_norm: 1.0
  -> optimizer: adam
  -> seq_length: 100
  -> vocab_size: 50
Test loss: 1.1067, perplexity: 3.02